{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGBClassifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPZX73poAI4dpNUvhBoTnmT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plaban1981/MachieHack/blob/master/XGBClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_pY8gz6SSDA",
        "colab_type": "text"
      },
      "source": [
        "##Extreme Gradient Boosting Classification\n",
        "\n",
        "Extreme Gradient Boosting, most popularly known as XGBoost is a gradient boosting algorithm that is used for both classification and regression problems. XGBoost is a star among hackathons as a winning algorithm. XGBoost provides a parallel tree boosting that solve many data science problems in a fast and accurate way.\n",
        "\n",
        "For a deeper understanding of XGB Classification, use the following resources:\n",
        "\n",
        "* XGBoost: A Scalable Tree Boosting System\n",
        "\n",
        "\n",
        "* XGBoost Documentation\n",
        "In this practise session, we will learn to code XGB Classifier. We will perform the following steps to build a simple classifier using the popular Iris dataset. You can find the dataset here.\n",
        "\n",
        "**Step 1. Data Preprocessing**\n",
        "\n",
        "- Importing the libraries.\n",
        "- Importing dataset (Dataset Link https://archive.ics.uci.edu/ml/datasets/iris).\n",
        "- Dealing with the categorical variable.\n",
        "- Classifying dependent and independent variables.\n",
        "- Splitting the data into a training set and test set.\n",
        "- Feature scaling.\n",
        "\n",
        "**Step 2. XGB Classification** \n",
        "\n",
        "- Create a XGB classifier.\n",
        "- Feed the training data to the classifier.\n",
        "- Predicting the species for the test set.\n",
        "- Using the confusion matrix to find accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvGrnxM_2001",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}